### 上午

- 早上起来大约🕢七点半左右，起床吃了几个煎饺，然后听了一个6minutes，主题是关于AI的，现对其中的单词进行简单回忆

  <u>frosted 结霜的</u>	 <u>osterd 牡蛎</u>	 <u>receipt 食谱</u>	 <u>balbulbee 大黄蜂</u> 	<u>trail and error 不断试错</u> 

  <u>earthworm 蚯蚓</u> 	<u>stride the answer 碰巧猜到答案</u> 	

  主要内容是说现在机器本身的头脑与蚯蚓相当，和人类还相差甚远，无法做出一些复杂的决定。机器学习就是不断地试错最终最小化犯错误的情况的过程

- 上午主要开始对毕业设计的论文部分进行构思，将论文的整体构架搭建完毕

### 中午

- 中午的时间用在了刷微博和看动漫上了，对于阅读的时间有所减少，这一点应该引起重视，尽量在中午减少对于刺激眼睛的电子设备的使用，可以多看一下kindle，但要注意午睡时间尽量早于12点50分

### 下午

- /#毕设 下午时间主要用在对于毕设论文的填充上，将原本的开题报告中整体构架部分进行了简单修改，同时在上网查找资料的过程中找到了7bot的运动学描述的论文(虽然是韩文的)，有了这个论文分析那就很好完成对于机械臂运动学分析部分的书写
- 五点钟左右去植物园阅读，开始先看了今日的RSS推送，有个不在应用内背单词的app很有意思，说是主要通过通知和提醒辅助对单词的记忆。在双语Chinadaily中学到短语 <u>世外桃源</u> emm 忘记英文了

### 晚上

- 晚上主要对白板ML中线性分类部分进行了总结

####  线性分类

##### 1 硬分类：直接输出类别

​	感知机：其中使用sigmoid函数对$w$^T^$x$进行分类，主要思想为错误驱动，目标函数是通过错误分类的和来定义的，优化时采用梯度下降法

​	线性判别分析：将输入按照一定的方向进行映射，使映射后的点满足“类间大，类内小”的特点，其中类内的距离用方差来表示，类间的距离用均值差的平方来表示，目标函数是$\frac{类内距离}{类间距离}$

##### 2 软分类：输出分类的概率值

​	2.1 判别模型：直接考虑后验分布

​		<u>逻辑回归</u> 判别模型直接考虑后验分布，最大化后验分布函数求最大值

​	2.2 生成模型：通过学习先验分布推导后验分布

​		1.<u>高斯判别分析</u> 在输出为0或1的情况下输入$x$都满足高斯分布，输出$y$满足伯努利分布，目标函数是联合分布函数，正比于先验分布和似然函数的成绩

​		2.<u>朴素贝叶斯</u> 假定所有的$x$​所有维度都是独立的，目标函数是最大会先验分布和似然函数的成绩，先验分布是分类模型，似然函数需考虑$x$是离散还是连续

- 晚上还对昨天的算法进行了复习以及学习了三种排序算法

  对于约瑟夫环的问题应该用递归的思想去解决，假设$f(n,m)$的值为最终返回的结果$y$,$f(n-1,m)=x$，我们需要建立两者关系以完成递归过程，经过运算$f(n,m)=(m+x)%n$

  三种排序算法主要是冒泡排序、选择排序、插入排序

  

> 今天任务完成工作较好，但是晚上写总结的时间过多导致睡眠时间可能不足，之后应适当缩短该项时间或者晚上提前开始写总结





























