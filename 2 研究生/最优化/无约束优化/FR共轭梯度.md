# 1.BFGS拟牛顿法



> 为什么要用拟牛顿法？

使用牛顿法对无约束优化问题进行求解时会用的海森矩阵的逆$\nabla f^2(x)^{-1}$,但是有时候由于海森矩阵并不是正定矩阵无法求出其逆，为了解决这种问题出现拟牛顿法。



## 1.1 算法流程

考虑 $f(x)$ 在当前点 $x^k$ 处的二次近似函数：

$$
m_k(x):= f(x^k)+ \nabla f(x^k)^T(x-x^k)+\frac{1}{2}(x-x^k)^TB_k(x-x^k)
$$

其中 $B_k\succ0$, 利用 $\min m_k(x)$ 得到搜索方向$d^k = -B_k^{-1}\nabla f(x^k)$,与牛顿法计算得到的搜索方向 $d^k = -\nabla f^2(x)^{-1} \nabla f(x^k)$ 相比，拟牛顿法使用矩阵 $B_k$ 代替海森矩阵 $\nabla f^2(x)$ ，在对 $B_k$ 进行计算的时候需要其满足拟牛顿条件:

$$
\nabla f(x^{k+1})-\nabla f(x^{k})=B_{k+1}(x^{k+1}-x^{k})
$$

记 $y_k:=\nabla f(x^{k+1})-\nabla f(x)$，$s_k:=x^{k+1}-x^{k}$, 上面的式子简化为：

$$
y_k = B_{k+1}s_k
$$

满足拟牛顿条件的矩阵有很多，基于已有的信息 $(y_k,s_k,B_k)$ , BFGS通过对 $B_k$ 进行校正得到 $B_{k+1}$令$B_{k+1}=B_k+\Delta B$, BFGS方法要求 $\Delta B$ 的秩为2，看做是对矩阵 $B_k$ 进行rank-2校正：

$$
(BFGS) \quad B_{k+1}=B_k-\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}+\frac{y_ky_k^T}{y_k^Ts_k}
$$

对整个算法框架进行总结：

**Step0：**设初始迭代点 $x^0$, 迭代终止条件 $ \varepsilon$ ，初始 $B_0=I$, $k:=0$

**Step1:** 判断是否达到终止迭代条件$||\nabla f(x_k)||\leq \varepsilon$

**Step2:** 计算下降方向 $d^k=-B_k^{-1}\nabla f(x^k)$

**Step3:** 计算步长 $\alpha_k$， 使用非精确搜索方式，步长需要满足强Wolfe条件

**Step4:** 令$x^{k+1}=x^{k}+\alpha_k d^k$， 更新$B_k$ ，令 $x^{k}=x^{k+1}$

在计算步长 $\alpha_k$ 的过程中，需要对其进行非精确线搜索，计算步骤如下图所示：

<img src="/Users/lianxing/Desktop/我的Markdown笔记/BFGS拟牛顿法.assets/1595305886.24296.png" alt="作业笔记：基于二次插值的Wolfe-Powell非精确线搜索算法及Python代码实现" style="zoom: 40%;" />

\## 1.2 BFGS拟牛顿法核心代码

整个算法的核心代码如下所示：

\```python

while np.linalg.norm(grad, ord=2) > 1e-10: #是否满足终止条件

\# 计算新的搜索方向

p = -1 * np.dot(np.linalg.inv(Bk), grad)

\#计算步长，需要满足强Wolfe条件

lam = compute_step(poly, vars, xk, 0.5, p, c2=0.9)

xk1 = xk + lam * p

\#更新Bk-->Bk+1

grad_k = getGrad(poly, xk, vars)

grad_k1 = getGrad(poly, xk1, vars)

sk = xk1 - xk

yk = grad_k1 - grad_k

skT_B_sk = np.dot(np.dot(sk.T,Bk),sk)

ykT_sk = np.dot(yk.T,sk)

Bk1 = Bk - np.dot(np.outer(np.dot(Bk,sk),sk.T),Bk)/skT_B_sk + np.outer(yk,yk.T)/ykT_sk

Bk =Bk1.astype(np.float)

grad = grad_k1

xk = xk1

\```


jnjknjknjk

\## 1.3 算法示例

**例1.给定函数 $f(x)=2x_1^2+3x_2^2+8x_2-9x_1+8$, 初始点 $x^0=[0,0]^T$, 使用BFGS算法求解最小值**

解：使用BFGS算法对上述函数最小值进行求解，运行代码得到的结果如下：

\```python

请输入函数的维数(整数)：2

请输入目标函数(自变量为x1-x2, 乘方为**)：2*x1**2+3*x2**2+8*x2-9*x1+8

2*x1**2 - 9*x1 + 3*x2**2 + 8*x2 + 8

========================================

迭代第1次时步长的值为:0.25

迭代第1次时方向的值为:[ 9. -8.]

迭代第1次后梯度范数值为: 4.0

迭代第1次后梯度值为:

[ 0. -4.]

迭代第1次后x的值为:

[ 2.25 -2. ]

迭代第1次后f(x)的值为:

-6.12500000000000

========================================

迭代第2次时步长的值为:

0.25

迭代第2次时方向的值为:

[1.59264579 1.86115101]

迭代第2次后梯度范数值为: 1.9991111601537106

迭代第2次后梯度值为:

[ 1.59264579 -1.20827348]

迭代第2次后x的值为:

[ 2.64816145 -1.53471225]

迭代第2次后f(x)的值为:

-7.01960785507119

========================================

······

=======================================

迭代第5次时步长的值为:

1

迭代第5次时方向的值为:

[8.53013553e-07 1.10317213e-06]

迭代第5次后梯度范数值为: 2.939738508868551e-09

迭代第5次后梯度值为:

[1.45675116e-09 2.55341703e-09]

迭代第5次后x的值为:

[ 2.25 -1.33333333]

迭代第5次后f(x)的值为:

-7.45833333333333

最终结果为：当自变量取值为[ 2.25 -1.33333333]时，函数值为-7.45833333333333

================== End =================

\```

该函数的函数图像下图所示：

<img src="/Users/lianxing/Desktop/我的Markdown笔记/BFGS拟牛顿法.assets/image-20210112094852598.png" alt="image-20210112094852598" style="zoom:67%;" />

**例2.给定函数 $f(x)=e^{x_1}(4x_1^2+2x_2^2+4x_1x_2+2x_2+1)$, 初始点 $x^0=[0,0]^T$, 使用BFGS算法求解最小值**

\```

================= Begin ================

请输入函数的维数(整数)：2

请输入目标函数(自变量为x1-x2, 乘方为**)：exp(x1)*(4*x1**2+2*x2**2+4*x1*x2+2*x2+1)

(4*x1**2 + 4*x1*x2 + 2*x2**2 + 2*x2 + 1)*exp(x1)

========================================

迭代第1次时步长的值为:

0.25

迭代第1次时方向的值为:

[-1. -2.]

迭代第1次后梯度范数值为: 2.278907364021062

迭代第1次后梯度值为:

[-2.14170215 -0.77880078]

迭代第1次后x的值为:

[-0.25 -0.5 ]

迭代第1次后f(x)的值为:

0.973500978839256

========================================

迭代第2次时步长的值为:

1

迭代第2次时方向的值为:

[ 0.74973444 -0.51483229]

迭代第2次后梯度范数值为: 0.14148218411536587

迭代第2次后梯度值为:

[-0.10054137 -0.09954216]

迭代第2次后x的值为:

[ 0.49973444 -1.01483229]

迭代第2次后f(x)的值为:

0.000751668814193529

========================================

······

========================================

迭代第9次时步长的值为:

1

迭代第9次时方向的值为:

[-2.35438842e-08 3.25975564e-08]

迭代第9次后梯度范数值为: 9.018709740740867e-10

迭代第9次后梯度值为:

[4.82214269e-10 7.62129027e-10]

迭代第9次后x的值为:

[ 0.5 -1. ]

迭代第9次后f(x)的值为:

-8.88178419700125e-16

最终结果为：当自变量取值为[ 0.5 -1. ]时，函数值为-8.88178419700125e-16

================== End =================

\```

当自变量取到 $x=[0.5 -1]$ 的时候取到局部极小值，此时得到的局部极小值为0

该函数的函数图像下图所示：

<img src="/Users/lianxing/Desktop/我的Markdown笔记/BFGS拟牛顿法.assets/image-20210112093804232.png" alt="image-20210112093804232" style="zoom: 80%;" />

\# 2. 共轭梯度法

考虑求解一个多元二次函数的极值问题：

$$
\min f(x):=\frac{1}{2}x^TQx-b^Tx+c
$$

该函数的的导数为 $\frac{df(x)}{dx}=Qx-b$, 求极值的过程就是使得一阶导数为0：

$$
\frac{df(x)}{dx}=Qx-b=0\Rightarrow Qx=b
$$

求解上式的过程就是求解 $Qx=b$, 假设记 $x^*$ 为真正的解，定义误差 $e_k=x^*-x_k$ ，其中 $x_t$ 是我们当前当前所处的位置

![image-20210112143901704](/Users/lianxing/Desktop/我的Markdown笔记/BFGS拟牛顿法.assets/image-20210112143901704.png)

所谓共轭梯度法就是保证在进行迭代更新的过程中保持每一个方向都走到了极致，换句话说就是如果当前误差方向与之前的更新方向正交的话那也就意味着之后不需要在这个方向上进行更新，如果记上一步方向为 $d_{k-1}$, 误差与上一步方向正交意味着 $d_{k-1}^Te_k=0$, 但在实际优化问题中我们并不知道最优解的位置也就不知道误差向量，但是我们可以有一个等价的做法就是共轭正交: $d_{k-1}^TQe_k=0$, 其中矩阵 $Q$ 是一个常对称矩阵，其作用相当于对右面的向量进行线性变换,下一个方向如果跟经过线性变换后的之前的所有方向都正交的话，那么某种意义上就永远不会走重复的方向。

\## 2.1.1 线性共轭梯度法

**线性共轭梯度法的步长**通过一维精确线搜索得到：

$$
\alpha_k=\arg\min\phi(\alpha)=f(x_k+\alpha d_k)=-\frac{\nabla f(x_k)d_k}{d_k^TQd_k}
$$

**线性共轭梯度法的方向**要求每一个方向之间都共轭正交，其中第一个方向取负梯度方向 $-\nabla f(x_0)$, 由于其余所有方向之间都要共轭正交，可以使用施密特正交化的原理去推导得到一组共轭正交的向量：

$$
d_k=-\nabla f(x_k)+\sum_{i<k}\frac{d_i^TQ\nabla f(x_k)}{d_i^TAd_i}d_i
$$

上面的式子理解为每一步的方向都是在起点的负梯度方向的基础上做修改, 也就是说进行施密特正交化的线性无关组是每一步终点的负梯度构成的。其中下一步中方向的第一部分就是当前位置的负梯度 $-\nabla f(x_k)$, 然后在这个基础上把它在其他方向上的共轭分量减去：

$$
d_k=-\nabla f(x_k)-\sum_{i<k}\frac{d_i^TQ[-\nabla f(x_k)]}{||d_i||^2_A}d_i
$$

对上面的式子进行化简，有共轭梯度法方向的更新公式：

$$
d_{k+1}=-\nabla f(x_{k+1})+\beta_kd_k ,\beta_k=\frac{\nabla f(x_{k+1})Qd_k}{d_k^TQd_k}
$$

对 $\beta_k$ 进一步化简有：

$$
\beta_k=\frac{\nabla f(x_{k+1})^T \nabla f(x_{k+1})}{\nabla f(x_{k})^T \nabla f(x_{k})}
$$

对共轭梯度法的算法框架进行总结：

**Step0：**设初始迭代点 $x^0$, 迭代终止条件 $ \varepsilon$ ，初始 $d_0:=-\nabla f(x^0)$, $k:=0$

**Step1:** 判断是否达到终止迭代条件$||\nabla f(x_k)||\leq \varepsilon$

**Step2:** 计算步长 $\alpha_k=-\frac{\nabla f(x_k)d_k}{d_k^TQd_k}$

**Step4:** 令$x_{k+1}=x_{k}+\alpha_k d_k$，并计算方向 $d_{k+1}=-\nabla f(x_{k+1})+\beta_kd_k$, 令 $k:=k+1$, 转Step1

\## 2.1.2 非线性共轭梯度法

非线性共轭梯度法分为FR方法和PRP方法，两者在对 $\beta_k$ 的计算上有所不同，整体的算法框架如下：

**Step0：**设初始迭代点 $x^0$, 迭代终止条件 $ \varepsilon$ ，初始 $d_0:=-\nabla f(x^0)$, $k:=0$

**Step1:** 判断是否达到终止迭代条件$||\nabla f(x_k)||\leq \varepsilon$

**Step2:** 利用线搜索计算步长 $\alpha_k$

**Step4:** 令$x_{k+1}=x_{k}+\alpha_k d_k$，并计算方向 $d_{k+1}=-\nabla f(x_{k+1})+\beta_kd_k$, 令 $k:=k+1$, 转Step1

其中 $\beta_k$ 的计算方式：

$$
(PRP)\quad \beta_k=\frac{\nabla f(x_{k+1})^T (\nabla f(x_{k+1})-\nabla f(x_{k}))}{\nabla f(x_{k})^T \nabla f(x_{k})}
$$

$$
(FR)\quad \beta_k=\frac{\nabla f(x_{k+1})^T \nabla f(x_{k+1})}{\nabla f(x_{k})^T \nabla f(x_{k})}
$$

\## 2.2 FR非线性共轭梯度法核心代码

\```python

while np.linalg.norm(grad_xk, ord=2) > 1e-7:

\#非线性共轭梯度法 FR

\#线搜索计算步长

lam = compute_step(poly, vars, xk, 1, pk, c2=0.1) #非线性共轭梯度

\#更新xk->xk+1

xk1 = xk + lam*pk

\#计算方向

grad_xk = getGrad(poly, xk, vars)

grad_xk1 = getGrad(poly,xk1,vars)

belta = np.dot(grad_xk1.T,grad_xk1)/np.dot(grad_xk.T,grad_xk)

pk1 = -grad_xk1 + belta*pk

direction = pk #更新前方向

pk = pk1

grad_xk = grad_xk1

xk = xk1

\```

\## 2.3 算法示例

**例1.给定函数 $f(x)=4x_1^2+3x_2^4+2x_1^2x_2-5x_2-3$, 初始点 $x^0=[0,0]^T$, 使用BFGS算法求解最小值**

\```python

================= Begin ================

请输入函数的维数(整数)：2

请输入目标函数(自变量为x1-x2, 乘方为**)：4*x1**2+3*x2**4+2*x1**2*x2-5*x2-3

2*x1**2*x2 + 4*x1**2 + 3*x2**4 - 5*x2 - 3

========================================

迭代第1次时梯度范数值为: 2.0703125

迭代第1次时步长的值为:

0.125

迭代第1次梯度值为:

[ 0. -2.0703125]

迭代第1次时方向的值为:

[-0. 5.]

迭代第1次时x的值为:

[0. 0.625]

迭代第1次时f(x)的值为:

-5.66723632812500

========================================

迭代第2次时梯度范数值为: 1.3295102069494673

迭代第2次时步长的值为:

0.0625

迭代第2次梯度值为:

[0. 1.32951021]

迭代第2次时方向的值为:

[-0. 2.92755127]

迭代第2次时x的值为:

[0. 0.80797195]

迭代第2次时f(x)的值为:

-5.76134308873851

========================================

……

========================================

迭代第10次时梯度范数值为: 8.055555333896791e-09

迭代第10次时步长的值为:

0.0625

迭代第10次梯度值为:

[ 0.00000000e+00 -8.05555533e-09]

迭代第10次时方向的值为:

[-0.00000000e+00 1.02354186e-07]

迭代第10次时x的值为:

[0. 0.74690079]

迭代第10次时f(x)的值为:

-5.80087796659823

最终结果为：当自变量取值为[0. 0.74690079]时，函数值为-5.80087796659823

================== End =================

\```

下面为函数图像，可以看到在 $x=[0 \quad0.7469]^T$的时候函数取到极小值

![b70bb276863a70ae00aabdd16783786b.png](evernotecid://63998C58-A2F3-420A-B36D-D04E3A26F84E/appyinxiangcom/32763492/ENResource/p30)

**例2.给定函数 $f(x)=sin(x_1)+2x_2^2$, 初始点 $x^0=[0,0]^T$, 使用BFGS算法求解最小值**

\```python

================ Begin ================

请输入函数的维数(整数)：2

请输入目标函数(自变量为x1-x2, 乘方为**)：sin(x1)+2*x2**2

2*x2**2 + sin(x1)

========================================

迭代第1次时梯度范数值为: 0.5403023058681398

迭代第1次时步长的值为:

1

迭代第1次梯度值为:

[0.54030231 0. ]

迭代第1次时方向的值为:

[-1. -0.]

迭代第1次时x的值为:

[-1. 0.]

迭代第1次时f(x)的值为:

-0.841470984807897

========================================

迭代第2次时梯度范数值为: 0.25846470002428185

迭代第2次时步长的值为:

1

迭代第2次梯度值为:

[-0.2584647 0. ]

迭代第2次时方向的值为:

[-0.83222889 -0. ]

迭代第2次时x的值为:

[-1.83222889 0. ]

迭代第2次时f(x)的值为:

-0.966020703112184

========================================

……

========================================

迭代第12次时梯度范数值为: 3.724889891549086e-08

迭代第12次时步长的值为:

1

迭代第12次梯度值为:

[3.72488989e-08 0.00000000e+00]

迭代第12次时方向的值为:

[ 2.91944771e-07 -0.00000000e+00]

迭代第12次时x的值为:

[-1.57079629 0. ]

迭代第12次时f(x)的值为:

-0.999999999999999

最终结果为：当自变量取值为[-1.57079629 0. ]时，函数值为-0.999999999999999

================== End =================

\```

当初始值为 $x_0=[0\quad0]^T$ 时求得的极小值点为 $x^*=[-1.57\quad0]^T$, 函数图像如下图所示：

![8fae30a0bc82e5b65633d3c26cfadd92.png](evernotecid://63998C58-A2F3-420A-B36D-D04E3A26F84E/appyinxiangcom/32763492/ENResource/p31)

尝试修改初始迭代点为 $x_0=[2\quad2]^T$, 再次使用共轭梯度法求解局部极小值点：

\```python

迭代第32次时梯度范数值为: 4.378246531264466e-08

迭代第32次时步长的值为:0.5

迭代第32次梯度值为:[-1.02555131e-08 4.25644067e-08]

迭代第32次时方向的值为:[-1.75939283e-07 -3.45706657e-08]

迭代第32次时x的值为:[4.71238897e+00 1.06411017e-08]

迭代第32次时f(x)的值为:-1.00000000000000

最终结果为：当自变量取值为[4.71238897e+00 1.06411017e-08]时，函数值为-1.00000000000000

\```

此时求得的极小值点为 $x^*=[4.71\quad0]^T$：