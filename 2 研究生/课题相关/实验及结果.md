# 所有进行实验

## 弱监督目标定位

- 2021.3.21

- [ ] ~~ACOL_BG 参数搜索，搜索的参数是BG_threshold，搜索范围是0-1，每一次使用30个epochs~~
- [ ] ~~BG 其中BG_rate=0.9 epochs=50~~ 

实验参数设置有问题，已经全部取消

- 2021.3.22

- [x] 1.实验探究加入背景loss后acol阈值大小对其的影响，实验日志名称CUB_VGG16_ACOLBG_GS_0_0.5.log 进程17276

```shell
CUDA_VISIBLE_DEVICES=7 nohup python main.py --experiment_name CUB_VGG16_ACOLBG_GS_0_0.5 --lr 0.00010569582 --large_feature_map True --wsol_method acol  --epochs 20 >CUB_VGG16_ACOLBG_GS_0_0.5.log&
```

实验结果：

```
Best trial:
  Value:  56.97273041076976
  Params: 
    acol_threshold: 0.09059378182721234
```

说明该方法没啥效果鸭，检查了一下代码，发现在背景部分loss的设置上存在问题，对于其loss的值没有取平均

```python
def get_loss(output_dict, gt_labels, **kwargs):
    bg_out = softmax_fun(output_dict['logit_b'])
    eps = torch.finfo(bg_out.dtype).eps
    entropy = torch.sum(bg_out * torch.log(1 / (bg_out + eps))) / bg_out.shape[0]
    back_loss = 5.3 - entropy #200个类别 当输出1/200时候信息熵最大为5.3

    return nn.CrossEntropyLoss()(output_dict['logits'], gt_labels.long()) + \
           back_loss/bg_out.shape[0]
```

修改代码后重新跑程序测试

- [x] 2.实验探究在BG方法下掩盖大小bg_rate对结果的影响，参数选择0.5-1，实验日志名称CUB_VGG16_BG_GS_0.5.log 进程19579

```shell
CUDA_VISIBLE_DEVICES=7 nohup python main_2.py --experiment_name CUB_VGG16_BG_GS_0.5_1 --lr 0.00001268269 --large_feature_map False --wsol_method bg  --epochs 20 >CUB_VGG16_BG_GS_0.5.log&
```

实验结果：

```shell
Best trial:
  Value:  64.85444712921414
  Params: 
    bg_grid_size: 0.7816447808766287
```

和只有CAM的结果改变不大

- [x] 3.实验研究加入attention结构后的CAM方法效果 日志名称CUB_VGG16_CAM_Attention.log 进程21593

```shell
CUDA_VISIBLE_DEVICES=7 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention --lr 0.00001268269 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention.log&
```

实验结果：

```python
Split train, metric loss, current value: 5.270277202467462
Split train, metric loss, best value: 5.269842646938982
Split train, metric loss, best epoch: 43
Split train, metric classification, current value: 0.9509509509509511
Split train, metric classification, best value: 0.9509509509509511
Split train, metric classification, best epoch: 50
Split val, metric classification, current value: 1.0
Split val, metric classification, best value: 1.0
Split val, metric classification, best epoch: 20
Split val, metric localization, current value: 36.699999999999996
Split val, metric localization, best value: 36.833333333333336
Split val, metric localization, best epoch: 40
Split val, metric localization_IOU_30, current value: 75.1
Split val, metric localization_IOU_30, best value: 76.0
Split val, metric localization_IOU_30, best epoch: 8
Split val, metric localization_IOU_50, current value: 29.3
Split val, metric localization_IOU_50, best value: 29.6
Split val, metric localization_IOU_50, best epoch: 38
Split val, metric localization_IOU_70, current value: 5.7
Split val, metric localization_IOU_70, best value: 5.9
Split val, metric localization_IOU_70, best epoch: 21
Split test, metric classification, current value: 0.8284432171211599
Split test, metric localization, current value: 40.85260614428719
Split test, metric localization_IOU_30, current value: 80.30721435968243
Split test, metric localization_IOU_50, current value: 35.329651363479464
Split test, metric localization_IOU_70, current value: 6.920952709699689
```

实验结果较差，可以看出来分类误差还很大，分类精度很低，可以适当调高学习率

- 2021.3.23

- [x] 4.实验依旧探究attention机制对于CAM影响，这次增加学习率 实验日志CUB_VGG16_CAM_Attention_lr_1_268269e_4.log 进程45897 

```shell
CUDA_VISIBLE_DEVICES=3 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_1_268269e_4 --lr 0.0001268269 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_1_268269e_4.log&
```

```shell
Final epoch evaluation on test set ...
Check train_log/CUB_VGG16_CAM_Attention_lr_1_268269e_4/last_checkpoint.pth.tar loaded.
Evaluate epoch 50, split test
Computing and evaluating cams.
Split train, metric loss, current value: 2.856503179799647
Split train, metric loss, best value: 2.853243201185474
Split train, metric loss, best epoch: 47
Split train, metric classification, current value: 34.15081748415082
Split train, metric classification, best value: 35.11845178511845
Split train, metric classification, best epoch: 38
Split val, metric classification, current value: 31.3
Split val, metric classification, best value: 31.3
Split val, metric classification, best epoch: 49
Split val, metric localization, current value: 53.13333333333333
Split val, metric localization, best value: 53.333333333333336
Split val, metric localization, best epoch: 40
Split val, metric localization_IOU_30, current value: 92.2
Split val, metric localization_IOU_30, best value: 92.3
Split val, metric localization_IOU_30, best epoch: 40
Split val, metric localization_IOU_50, current value: 54.7
Split val, metric localization_IOU_50, best value: 55.2
Split val, metric localization_IOU_50, best epoch: 43
Split val, metric localization_IOU_70, current value: 12.5
Split val, metric localization_IOU_70, best value: 13.2
Split val, metric localization_IOU_70, best epoch: 24
Split test, metric classification, current value: 33.914394200897476
Split test, metric localization, current value: 58.84823380508572
Split test, metric localization_IOU_30, current value: 96.2202278218847
Split test, metric localization_IOU_50, current value: 64.96375560925095
Split test, metric localization_IOU_70, current value: 15.360717984121505
```

通过实验4看出来当学习率调大的时候加入attention机制后模型定位效果显然更好，尝试再次增加学习率观察实验效果

- [x] 5.实验探究学习率对于加入attention机制后cam影响，从log分布中选择学习率，范围是1e-2-1e-5 实验日志 CUB_VGG16_CAM_Attention_lr_search.log 进程48110

```shell
CUDA_VISIBLE_DEVICES=3 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_search  --large_feature_map False --wsol_method cam_attention  --epochs 20 >CUB_VGG16_CAM_Attention_lr_search.log&
```

实验效果非常差：

```python
Best trial:
  Value:  42.44045564376942
  Params: 
    learning_rate: 0.0002569654893660818
```



2021.3.24

- [x] 6.在实验四的基础上，实验依旧探究attention机制对于CAM影响，这次增加学习率到2.536538e-4 实验日志CUB_VGG16_CAM_Attention_lr_2_536538e_4.log 进程42980

```shell
CUDA_VISIBLE_DEVICES=1 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_2_536538e_4 --lr 0.000253658 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_2_536538e_4.log&
```

效果的确更好了，但是和纯CAM的方式还是有差距

```python
Split test, metric classification, current value: 60.2865032792544
Split test, metric localization, current value: 60.303762512944424
Split test, metric localization_IOU_30, current value: 96.96237487055575
Split test, metric localization_IOU_50, current value: 68.51915774939593
Split test, metric localization_IOU_70, current value: 15.429754918881601
```

在进行实验6的时候对于VggCam_Attention结构没有➕conv6，现在把conv6加入进行实验8

2021.3.25

- [ ] 7.在实验一的基础上对于改变了loss的设置后重新进行实验，实验日志CUB_VGG16_ACOLBG_GS_V2.log 选取acol_threshold=0.2 进程号33830

```shell
CUDA_VISIBLE_DEVICES=7 nohup python main.py --experiment_name CUB_VGG16_ACOLBG_GS_V2 --lr 0.00010569582 --large_feature_map True --wsol_method acol  --epochs 50 --acol_threshold 0.2 >CUB_VGG16_ACOLBG_GS_V2.log&
```

- [ ] 8.在实验6的基础上加入conv6 实验日志CUB_VGG16_CAM_Attention_lr_2_536538e_4_exp8.log 实验进程12658

```shell
CUDA_VISIBLE_DEVICES=7 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_2_536538e_4_exp8 --lr 0.000253658 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_2_536538e_4_exp8.log&
```







