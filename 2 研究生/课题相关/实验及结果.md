# 所有进行实验

## 弱监督目标定位

- 2021.3.21

- [ ] ~~ACOL_BG 参数搜索，搜索的参数是BG_threshold，搜索范围是0-1，每一次使用30个epochs~~
- [ ] ~~BG 其中BG_rate=0.9 epochs=50~~ 

实验参数设置有问题，已经全部取消

- 2021.3.22

- [x] 1.实验探究加入背景loss后acol阈值大小对其的影响，实验日志名称CUB_VGG16_ACOLBG_GS_0_0.5.log 进程17276

```shell
CUDA_VISIBLE_DEVICES=7 nohup python main.py --experiment_name CUB_VGG16_ACOLBG_GS_0_0.5 --lr 0.00010569582 --large_feature_map True --wsol_method acol  --epochs 20 >CUB_VGG16_ACOLBG_GS_0_0.5.log&
```

实验结果：

```
Best trial:
  Value:  56.97273041076976
  Params: 
    acol_threshold: 0.09059378182721234
```

说明该方法没啥效果鸭，检查了一下代码，发现在背景部分loss的设置上存在问题，对于其loss的值没有取平均

```python
def get_loss(output_dict, gt_labels, **kwargs):
    bg_out = softmax_fun(output_dict['logit_b'])
    eps = torch.finfo(bg_out.dtype).eps
    entropy = torch.sum(bg_out * torch.log(1 / (bg_out + eps))) / bg_out.shape[0]
    back_loss = 5.3 - entropy #200个类别 当输出1/200时候信息熵最大为5.3

    return nn.CrossEntropyLoss()(output_dict['logits'], gt_labels.long()) + \
           back_loss/bg_out.shape[0]
```

修改代码后重新跑程序测试

- [x] 2.实验探究在BG方法下掩盖大小bg_rate对结果的影响，参数选择0.5-1，实验日志名称CUB_VGG16_BG_GS_0.5.log 进程19579

```shell
CUDA_VISIBLE_DEVICES=7 nohup python main_2.py --experiment_name CUB_VGG16_BG_GS_0.5_1 --lr 0.00001268269 --large_feature_map False --wsol_method bg  --epochs 20 >CUB_VGG16_BG_GS_0.5.log&
```

实验结果：

```shell
Best trial:
  Value:  64.85444712921414
  Params: 
    bg_grid_size: 0.7816447808766287
```

和只有CAM的结果改变不大

- [x] 3.实验研究加入attention结构后的CAM方法效果 日志名称CUB_VGG16_CAM_Attention.log 进程21593

```shell
CUDA_VISIBLE_DEVICES=7 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention --lr 0.00001268269 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention.log&
```

实验结果：

```python
Split train, metric loss, current value: 5.270277202467462
Split train, metric loss, best value: 5.269842646938982
Split train, metric loss, best epoch: 43
Split train, metric classification, current value: 0.9509509509509511
Split train, metric classification, best value: 0.9509509509509511
Split train, metric classification, best epoch: 50
Split val, metric classification, current value: 1.0
Split val, metric classification, best value: 1.0
Split val, metric classification, best epoch: 20
Split val, metric localization, current value: 36.699999999999996
Split val, metric localization, best value: 36.833333333333336
Split val, metric localization, best epoch: 40
Split val, metric localization_IOU_30, current value: 75.1
Split val, metric localization_IOU_30, best value: 76.0
Split val, metric localization_IOU_30, best epoch: 8
Split val, metric localization_IOU_50, current value: 29.3
Split val, metric localization_IOU_50, best value: 29.6
Split val, metric localization_IOU_50, best epoch: 38
Split val, metric localization_IOU_70, current value: 5.7
Split val, metric localization_IOU_70, best value: 5.9
Split val, metric localization_IOU_70, best epoch: 21
Split test, metric classification, current value: 0.8284432171211599
Split test, metric localization, current value: 40.85260614428719
Split test, metric localization_IOU_30, current value: 80.30721435968243
Split test, metric localization_IOU_50, current value: 35.329651363479464
Split test, metric localization_IOU_70, current value: 6.920952709699689
```

实验结果较差，可以看出来分类误差还很大，分类精度很低，可以适当调高学习率

- 2021.3.23

- [x] 4.实验依旧探究attention机制对于CAM影响，这次增加学习率 实验日志CUB_VGG16_CAM_Attention_lr_1_268269e_4.log 进程45897 

```shell
CUDA_VISIBLE_DEVICES=3 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_1_268269e_4 --lr 0.0001268269 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_1_268269e_4.log&
```

```shell
Final epoch evaluation on test set ...
Check train_log/CUB_VGG16_CAM_Attention_lr_1_268269e_4/last_checkpoint.pth.tar loaded.
Evaluate epoch 50, split test
Computing and evaluating cams.
Split train, metric loss, current value: 2.856503179799647
Split train, metric loss, best value: 2.853243201185474
Split train, metric loss, best epoch: 47
Split train, metric classification, current value: 34.15081748415082
Split train, metric classification, best value: 35.11845178511845
Split train, metric classification, best epoch: 38
Split val, metric classification, current value: 31.3
Split val, metric classification, best value: 31.3
Split val, metric classification, best epoch: 49
Split val, metric localization, current value: 53.13333333333333
Split val, metric localization, best value: 53.333333333333336
Split val, metric localization, best epoch: 40
Split val, metric localization_IOU_30, current value: 92.2
Split val, metric localization_IOU_30, best value: 92.3
Split val, metric localization_IOU_30, best epoch: 40
Split val, metric localization_IOU_50, current value: 54.7
Split val, metric localization_IOU_50, best value: 55.2
Split val, metric localization_IOU_50, best epoch: 43
Split val, metric localization_IOU_70, current value: 12.5
Split val, metric localization_IOU_70, best value: 13.2
Split val, metric localization_IOU_70, best epoch: 24
Split test, metric classification, current value: 33.914394200897476
Split test, metric localization, current value: 58.84823380508572
Split test, metric localization_IOU_30, current value: 96.2202278218847
Split test, metric localization_IOU_50, current value: 64.96375560925095
Split test, metric localization_IOU_70, current value: 15.360717984121505
```

通过实验4看出来当学习率调大的时候加入attention机制后模型定位效果显然更好，尝试再次增加学习率观察实验效果

- [x] 5.实验探究学习率对于加入attention机制后cam影响，从log分布中选择学习率，范围是1e-2-1e-5 实验日志 CUB_VGG16_CAM_Attention_lr_search.log 进程48110

```shell
CUDA_VISIBLE_DEVICES=3 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_search  --large_feature_map False --wsol_method cam_attention  --epochs 20 >CUB_VGG16_CAM_Attention_lr_search.log&
```

实验效果非常差：

```python
Best trial:
  Value:  42.44045564376942
  Params: 
    learning_rate: 0.0002569654893660818
```



2021.3.24

- [x] 6.在实验四的基础上，实验依旧探究attention机制对于CAM影响，这次增加学习率到2.536538e-4 实验日志CUB_VGG16_CAM_Attention_lr_2_536538e_4.log 进程42980

```shell
CUDA_VISIBLE_DEVICES=1 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_2_536538e_4 --lr 0.000253658 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_2_536538e_4.log&
```

效果的确更好了，但是和纯CAM的方式还是有差距

```python
Split test, metric classification, current value: 60.2865032792544
Split test, metric localization, current value: 60.303762512944424
Split test, metric localization_IOU_30, current value: 96.96237487055575
Split test, metric localization_IOU_50, current value: 68.51915774939593
Split test, metric localization_IOU_70, current value: 15.429754918881601
```

在进行实验6的时候对于VggCam_Attention结构没有➕conv6，现在把conv6加入进行实验8

2021.3.25

- [x] 7.在实验一的基础上对于改变了loss的设置后重新进行实验，实验日志CUB_VGG16_ACOLBG_GS_V2.log 选取acol_threshold=0.2 进程号33830

```shell
CUDA_VISIBLE_DEVICES=7 nohup python main.py --experiment_name CUB_VGG16_ACOLBG_GS_V2 --lr 0.00010569582 --large_feature_map True --wsol_method acol  --epochs 50 --acol_threshold 0.2 >CUB_VGG16_ACOLBG_GS_V2.log&
```

```python
Split test, metric classification, current value: 71.31515360717984
Split test, metric localization, current value: 56.667817282246006
Split test, metric localization_IOU_30, current value: 92.61304798066966
Split test, metric localization_IOU_50, current value: 61.995167414566794
Split test, metric localization_IOU_70, current value: 15.395236451501553
```

看来loss设置方式没有错

- [x] 8.在实验6的基础上加入conv6 实验日志CUB_VGG16_CAM_Attention_lr_2_536538e_4_exp8.log 实验进程12658

```shell
CUDA_VISIBLE_DEVICES=7 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_2_536538e_4_exp8 --lr 0.000253658 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_2_536538e_4_exp8.log&
```

```
Split test, metric classification, current value: 67.0693821194339
Split test, metric localization, current value: 61.696007363939714
Split test, metric localization_IOU_30, current value: 97.10044874007595
Split test, metric localization_IOU_50, current value: 70.2105626510183
Split test, metric localization_IOU_70, current value: 17.777010700724887
```

效果好于之前，但是还是不如纯CAM的方式

- [x] 9.在实验8基础上attention作为残差结构输入 进程38701

```
CUDA_VISIBLE_DEVICES=0 nohup python test_attention.py --experiment_name CUB_VGG16_CAM_Attention_lr_2_536538e_4_v2 --lr 0.000253658 --large_feature_map False --wsol_method cam_attention  --epochs 50 >CUB_VGG16_CAM_Attention_lr_2_536538e_4_v2.log&
```

实验效果很差，从第一个epochs开始定位精度就没有提高了

```
Split test, metric localization, current value: 56.88068116442296
Split test, metric localization_IOU_30, current value: 94.58060062133241
Split test, metric localization_IOU_50, current value: 62.58198136002761
Split test, metric localization_IOU_70, current value: 13.479461511908871

```

- [x] 10.在ADL基础上加入BG 进程43969

```
CUDA_VISIBLE_DEVICES=8 nohup python main_2.py --experiment_name CUB_VGG16_ADLBG --lr 0.00002430601 --large_feature_map False --wsol_method adl --adl_threshold 0.72 --adl_drop_rate 0.33  --epochs 50 --bg_grid_size 0.78 >CUB_VGG16_ADLBG.log&
```

```python
Split test, metric classification, current value: 65.70590265792198
Split test, metric localization, current value: 62.904153722241404
Split test, metric localization_IOU_30, current value: 98.10148429409735
Split test, metric localization_IOU_50, current value: 74.0766309975837
Split test, metric localization_IOU_70, current value: 16.534345875043147
```

比单纯ADL效果要差，尝试减少学习率

- [ ] 11.在10基础上（ADL+BG）减少学习率，进程号26263

```
CUDA_VISIBLE_DEVICES=3 nohup python main_2.py --experiment_name CUB_VGG16_ADLBG_v2 --lr 0.000012 --large_feature_map False --wsol_method adl --adl_threshold 0.72 --adl_drop_rate 0.33  --epochs 50 --bg_grid_size 0.78 >CUB_VGG16_ADLBG_v2.log&
```

效果很好

```python
Split test, metric classification, current value: 54.02140144977563
Split test, metric localization, current value: 66.19491427913934
Split test, metric localization_IOU_30, current value: 97.9979288919572
Split test, metric localization_IOU_50, current value: 78.66758715913014
Split test, metric localization_IOU_70, current value: 21.919226786330686
```

现在换成batch_size 32试一下 进程30266

```
CUDA_VISIBLE_DEVICES=0 nohup python main_2.py --experiment_name CUB_VGG16_ADLBG_v2 --lr 0.000012 --large_feature_map False --wsol_method adl --adl_threshold 0.72 --adl_drop_rate 0.33  --epochs 50 --bg_grid_size 0.78 --batch_size 32 >CUB_VGG16_ADLBG_v2.log&
```



- [x] 12.重现ADL实验代码 进程号27369

```
CUDA_VISIBLE_DEVICES=3 nohup python main.py --experiment_name CUB_VGG16_ADL --lr 0.00002430601 --large_feature_map False --wsol_method adl --adl_threshold 0.72 --adl_drop_rate 0.33  --epochs 50  >CUB_VGG16_ADL.log&
```

```
Split test, metric classification, current value: 64.4977562996203
Split test, metric localization, current value: 61.67299505235301
Split test, metric localization_IOU_30, current value: 96.89333793579566
Split test, metric localization_IOU_50, current value: 71.79841215050052
Split test, metric localization_IOU_70, current value: 16.327235070762857
```

检查了一下 发现batch设置成了16原文是32，修改之后再次进行实验复现

- [x] 13.重现ADL实验 进程号 6951

```
CUDA_VISIBLE_DEVICES=9 nohup python main.py --experiment_name CUB_VGG16_ADL --lr 0.00002430601 --large_feature_map False --wsol_method adl --adl_threshold 0.72 --adl_drop_rate 0.33  --epochs 50 --batch_size 32 >CUB_VGG16_ADL.log&
```

```
Split test, metric classification, current value: 55.76458405246807
Split test, metric localization, current value: 65.32619951674145
Split test, metric localization_IOU_30, current value: 97.34207801173628
Split test, metric localization_IOU_50, current value: 76.70003451846738
Split test, metric localization_IOU_70, current value: 21.936486020020713
```

- [x] **14.改进了生成cam的机制，直接对各个层相加 进程号7878**

```
CUDA_VISIBLE_DEVICES=2 nohup python main.py --experiment_name CUB_VGG16_CAMV1 --lr 0.00001268269 --large_feature_map False --wsol_method cam --epochs 50 --batch_size 32 >CUB_VGG16_CAMV1.log&
```

效果非常好

```
Split test, metric classification, current value: 50.43148084225061
Split test, metric localization, current value: 68.84708318950639
Split test, metric localization_IOU_30, current value: 98.96444597859855
Split test, metric localization_IOU_50, current value: 82.67172937521575
Split test, metric localization_IOU_70, current value: 24.905074214704868

```



- [ ] **未使用mixcam：**现在使用其他model继续实验，使用resnet50进行实验 进程15257 CUB_Resnet16_CAMV1.log

```
CUDA_VISIBLE_DEVICES=1 nohup python main.py --architecture resnet50 --experiment_name CUB_Resnet16_CAMV1 --lr 0.00023222617 --weight_decay 0.0001 --large_feature_map True --wsol_method cam --epochs 50 --batch_size 32 >CUB_Resnet16_CAMV1.log&
```

- [ ] **未使用mixcam：**使用inception_v3进行实验 进程15598 CUB_inception_v3_CAMV1.log

```
CUDA_VISIBLE_DEVICES=6 nohup python main.py --architecture inception_v3 --experiment_name CUB_Inception_v3_CAMV1 --lr 0.00224844746 --weight_decay 0.0005 --large_feature_map True --wsol_method cam --epochs 50 --batch_size 32 >CUB_inception_v3_CAMV1.log&
```



- [ ] **使用mixcam：**resnet50进行实验 进程15257 CUB_Resnet16_MixCAM_V0.log 进程21072

```
CUDA_VISIBLE_DEVICES=7 nohup python main.py --architecture resnet50 --experiment_name CUB_Resnet16_MixCAM_V0 --lr 0.00023222617 --weight_decay 0.0001 --large_feature_map True --wsol_method cam --epochs 50 --batch_size 32 --mixcam True >CUB_Resnet16_MixCAM_V0.log&
```

- [ ] **使用mixcam**：inception_v3进行实验 进程15257 CUB_inception_v3_MixCAM_V0.log 进程21449

```
CUDA_VISIBLE_DEVICES=4 nohup python main.py --architecture inception_v3 --experiment_name CUB_inception_v3_MixCAM_V0 --lr 0.00224844746 --weight_decay 0.0005 --large_feature_map True --wsol_method cam --epochs 50 --batch_size 32 --mixcam True >CUB_inception_v3_MixCAM_V0.log&
```



- **使用mixcam**：inception_v3进行实验，这次试用分类top10的cam

```
CUDA_VISIBLE_DEVICES=4 nohup python main.py --architecture inception_v3 --experiment_name CUB_inception_v3_MixCAM_V1 --lr 0.00224844746 --weight_decay 0.0005 --large_feature_map True --wsol_method cam --epochs 50 --batch_size 32 --mixcam True >CUB_inception_v3_MixCAM_V1.log&
```



